{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "import vecstack\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_df(filename, valtype):\n",
    "    df = pd.read_csv(filename, low_memory=False, dtype=valtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "def create_combined_df(input_dict):\n",
    "    fdf = pd.DataFrame()\n",
    "    cols = OrderedDict()\n",
    "    for k, v in input_dict.items():\n",
    "        df = read_df('./data/'+k, v)\n",
    "        colnames = [c for c in df.columns if c not in ['None', 'Unnamed: 0']]\n",
    "        cols[k] = colnames\n",
    "        fdf = pd.concat([fdf, df], axis=1)\n",
    "    \n",
    "    # fdf = fdf.DataFrame(fdf, columns=cols)\n",
    "    fdf = fdf.drop(['None', 'Unnamed: 0'], axis=1)\n",
    "    return fdf, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dependent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68848</th>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "68848                  95.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(base+'fin_train_indeps.csv', encoding='utf8')\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis=1)\n",
    "y_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.,  90.,\n",
       "        91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "33353                  95.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(base+'fin_test_indeps.csv', encoding='utf8')\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis=1)\n",
    "y_test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.,  90.,\n",
       "        91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read independent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_train = pd.read_csv(base+'fin_num_train_deps.csv')\n",
    "comb_train = comb_train.drop(['Unnamed: 0'], axis=1)\n",
    "comb_test = pd.read_csv(base+'fin_num_test_deps.csv')\n",
    "comb_test = comb_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test data into Holdout and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "idxs = np.random.randint(0, y_test.shape[0], y_test.shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_validation = y_test.iloc[~y_test.index.isin(idxs)]\n",
    "y_holdout = y_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_validation = comb_test.iloc[~comb_test.index.isin(idxs)]\n",
    "comb_holdout = comb_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Objective: Implement a wrapper for vecstack\n",
    "# Input scikit model instances and training data\n",
    "# Output: Predictions\n",
    "\n",
    "import xgboost\n",
    "import dill as pickle\n",
    "from copy import deepcopy \n",
    "from vecstack import StackingTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class VecstackRunner():\n",
    "\n",
    "    def __init__(self, X, y, Xt, yt, l1_estimators, l2_estimator, prfx='', metric='rmse', regression=True, nfolds=10, verbose=2):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Xt = Xt\n",
    "        self.yt = yt\n",
    "        self.yp = None\n",
    "        self.ytp = None\n",
    "        self.l1 = l1_estimators\n",
    "        self.l2 = l2_estimator\n",
    "        self.prfx = prfx\n",
    "        self.metname = metric\n",
    "        self.nf = nfolds\n",
    "        self.v = verbose\n",
    "        self.is_reg = regression\n",
    "        self.stack = None\n",
    "    \n",
    "    def mse(self, actual, pred):\n",
    "        return mean_squared_error(actual, pred)\n",
    "    \n",
    "    def rsq(self, actual, pred):\n",
    "        return r2_score(actual, pred)\n",
    "    \n",
    "    def get_metric_calc(self, actual, pred):\n",
    "        if 'rmse' == self.metname:\n",
    "            return self.mse(actual, pred)\n",
    "        elif 'r2' == self.metname:\n",
    "            return self.rsq(actual, pred)\n",
    "    \n",
    "    def build_stack(self):\n",
    "        self.stack = StackingTransformer(self.l1, \n",
    "                                        regression=self.is_reg, \n",
    "                                        shuffle=True, \n",
    "                                        n_folds=self.nf, \n",
    "                                        metric=self.get_metric_calc, \n",
    "                                        verbose=self.v)\n",
    "    \n",
    "    def fit_stack(self):\n",
    "        return self.stack.fit(self.X, self.y)\n",
    "    \n",
    "    def transform(self):\n",
    "        self.X = self.stack.transform(self.X)\n",
    "        self.Xt = self.stack.transform(self.Xt)\n",
    "    \n",
    "    def fit_l2(self):\n",
    "        self.l2.fit(self.X, self.y)\n",
    "    \n",
    "    def predict(self):\n",
    "        self.yp = self.l2.predict(self.X)\n",
    "        self.ytp = self.l2.predict(self.Xt)\n",
    "    \n",
    "    def calculate_error(self, calc=None):\n",
    "        if calc:\n",
    "            y_err = calc(self.y, self.yp)\n",
    "            yp_err = calc(self.y, self.ytp)\n",
    "        else:\n",
    "            y_err = self.get_metric_calc(self.y, self.yp)\n",
    "            yt_err = self.get_metric_calc(self.yt, self.ytp)\n",
    "            \n",
    "        return [('Train err', y_err), ('Test err', yt_err)]\n",
    "    \n",
    "    def save_to_disk(self):\n",
    "        sname = self.prfx+'_vecstack_stack.pkl'\n",
    "        cname = self.prfx+'_vecstack_clf.pkl'\n",
    "        \n",
    "        with open('./data/'+sname, 'wb') as f:\n",
    "            pickle.dump(self.stack,f)\n",
    "        \n",
    "        with open('./data/'+cname, 'wb') as f:\n",
    "            pickle.dump(self.l2, f)\n",
    "    \n",
    "    def run(self):\n",
    "        self.build_stack()\n",
    "        self.fit_stack()\n",
    "        self.transform()\n",
    "        self.fit_l2()\n",
    "        self.predict()\n",
    "        self.save_to_disk()\n",
    "        return self.calculate_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils.seq_dataset import ArrayDataset, CSRDataset\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/least_angle.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:29: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import cd_fast\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sag_fast import sag\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm, liblinear\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm_sparse\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ball_tree import BallTree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .kd_tree import KDTree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._criterion import Criterion\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/gradient_boosting.py:34: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "en = ElasticNet(alpha=0.01)\n",
    "# lass = Lasso(alpha=0.001, fit_intercept=False, max_iter=1000)\n",
    "ridge = Ridge(normalize=False, alpha=0.1, max_iter=1000)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, \n",
    "                               subsample=0.75, max_depth=15)\n",
    "ab = AdaBoostRegressor(n_estimators=100, learning_rate=0.01)\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                           gamma=0, subsample=0.5, \n",
    "                           max_depth=15, objective='reg:linear')\n",
    "randf = RandomForestRegressor(n_estimators=100, min_samples_split=10)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [get_metric_calc]\n",
      "variant:      [A]\n",
      "n_estimators: [5]\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    fold  0:  [25.00591516]\n",
      "    fold  1:  [24.23885316]\n",
      "    fold  2:  [24.82456530]\n",
      "    fold  3:  [24.69612564]\n",
      "    fold  4:  [24.89407189]\n",
      "    fold  5:  [24.74023223]\n",
      "    fold  6:  [24.15592378]\n",
      "    fold  7:  [25.17248708]\n",
      "    fold  8:  [24.76209495]\n",
      "    fold  9:  [24.16777565]\n",
      "    ----\n",
      "    MEAN:     [24.66580448] + [0.33996217]\n",
      "\n",
      "estimator  1: [ridge: Ridge]\n",
      "    fold  0:  [24.84626702]\n",
      "    fold  1:  [24.15791872]\n",
      "    fold  2:  [24.73046735]\n",
      "    fold  3:  [24.57766215]\n",
      "    fold  4:  [24.79482557]\n",
      "    fold  5:  [24.60719441]\n",
      "    fold  6:  [24.10384777]\n",
      "    fold  7:  [25.02842276]\n",
      "    fold  8:  [24.64489486]\n",
      "    fold  9:  [23.99845465]\n",
      "    ----\n",
      "    MEAN:     [24.54899552] + [0.32850931]\n",
      "\n",
      "estimator  2: [gb: GradientBoostingRegressor]\n",
      "    fold  0:  [19.39354709]\n",
      "    fold  1:  [18.70054193]\n",
      "    fold  2:  [19.21136551]\n",
      "    fold  3:  [19.13892118]\n",
      "    fold  4:  [19.23203617]\n",
      "    fold  5:  [19.32389113]\n",
      "    fold  6:  [19.02246042]\n",
      "    fold  7:  [19.49525811]\n",
      "    fold  8:  [19.36918016]\n",
      "    fold  9:  [18.56845329]\n",
      "    ----\n",
      "    MEAN:     [19.14556550] + [0.28700064]\n",
      "\n",
      "estimator  3: [ab: AdaBoostRegressor]\n",
      "    fold  0:  [24.29825795]\n",
      "    fold  1:  [23.59577226]\n",
      "    fold  2:  [24.14958179]\n",
      "    fold  3:  [23.89863415]\n",
      "    fold  4:  [24.12147329]\n",
      "    fold  5:  [23.94966947]\n",
      "    fold  6:  [23.54729911]\n",
      "    fold  7:  [24.32403381]\n",
      "    fold  8:  [24.12672708]\n",
      "    fold  9:  [23.45618238]\n",
      "    ----\n",
      "    MEAN:     [23.94676313] + [0.29928051]\n",
      "\n",
      "estimator  4: [randf: RandomForestRegressor]\n",
      "    fold  0:  [15.90135496]\n",
      "    fold  1:  [15.26982203]\n",
      "    fold  2:  [15.57251792]\n",
      "    fold  3:  [15.85912317]\n",
      "    fold  4:  [15.71105292]\n",
      "    fold  5:  [15.83013636]\n",
      "    fold  6:  [15.85634746]\n",
      "    fold  7:  [16.05072911]\n",
      "    fold  8:  [15.97432677]\n",
      "    fold  9:  [15.54205661]\n",
      "    ----\n",
      "    MEAN:     [15.75674673] + [0.22353550]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [ridge: Ridge]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [gb: GradientBoostingRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [ab: AdaBoostRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  4: [randf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [ridge: Ridge]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [gb: GradientBoostingRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [ab: AdaBoostRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  4: [randf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Train err', 12.795743146522257), ('Test err', 15.062838458618787)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                # ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "base = './data/'\n",
    "prf = 'num'\n",
    "vr = VecstackRunner(comb_train, y_train, \n",
    "                    comb_validation, y_validation, \n",
    "                    estimators, xgb, prfx=prf, nfolds=10)\n",
    "vr.run()\n",
    "\n",
    "# print mean_squared_error(y_validation, tc.predict(ts.transform(comb_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [ridge: Ridge]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [gb: GradientBoostingRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [ab: AdaBoostRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  4: [randf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [ridge: Ridge]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [gb: GradientBoostingRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [ab: AdaBoostRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  4: [randf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "####################\n",
      "Column: num\n",
      "Train: \n",
      "MSE: 12.795743146522257\n",
      "R2: 0.496120275250133\n",
      "Test: \n",
      "MSE: 15.034565244717642\n",
      "R2: 0.3945334950759255\n",
      "####################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "\n",
    "Xt = ts.transform(comb_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(comb_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31006363, 0.15101421, 0.20756777, 0.15036593, 0.18098845],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

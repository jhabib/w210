{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "import vecstack\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename, valtype):\n",
    "    df = pd.read_csv(filename, low_memory=False, dtype=valtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "def create_combined_df(input_dict):\n",
    "    fdf = pd.DataFrame()\n",
    "    cols = OrderedDict()\n",
    "    for k, v in input_dict.items():\n",
    "        df = read_df('./data/'+k, v)\n",
    "        colnames = [c for c in df.columns if c not in ['None', 'Unnamed: 0']]\n",
    "        cols[k] = colnames\n",
    "        fdf = pd.concat([fdf, df], axis=1)\n",
    "    \n",
    "    # fdf = fdf.DataFrame(fdf, columns=cols)\n",
    "    fdf = fdf.drop(['None', 'Unnamed: 0'], axis=1)\n",
    "    return fdf, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dependent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95166</th>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "95166                  96.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(base+'fin_train_indeps.csv', encoding='utf8')\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis=1)\n",
    "y_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.,  90.,\n",
       "        91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6676</th>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_scores_rating\n",
       "6676                  88.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(base+'fin_test_indeps.csv', encoding='utf8')\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis=1)\n",
    "y_test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.,  90.,\n",
       "        91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read independent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train = pd.read_csv(base+'fin_comb_train_deps.csv')\n",
    "comb_train = comb_train.drop(['Unnamed: 0'], axis=1)\n",
    "comb_test = pd.read_csv(base+'fin_comb_test_deps.csv')\n",
    "comb_test = comb_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test data into Holdout and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "idxs = np.random.randint(0, y_test.shape[0], y_test.shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = y_test.iloc[~y_test.index.isin(idxs)]\n",
    "y_holdout = y_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_validation = comb_test.iloc[~comb_test.index.isin(idxs)]\n",
    "comb_holdout = comb_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective: Implement a wrapper for vecstack\n",
    "# Input scikit model instances and training data\n",
    "# Output: Predictions\n",
    "\n",
    "import xgboost\n",
    "import dill as pickle\n",
    "from copy import deepcopy \n",
    "from vecstack import StackingTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class VecstackRunner():\n",
    "\n",
    "    def __init__(self, X, y, Xt, yt, l1_estimators, l2_estimator, prfx='', metric='rmse', regression=True, nfolds=10, verbose=2):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Xt = Xt\n",
    "        self.yt = yt\n",
    "        self.yp = None\n",
    "        self.ytp = None\n",
    "        self.l1 = l1_estimators\n",
    "        self.l2 = l2_estimator\n",
    "        self.prfx = prfx\n",
    "        self.metname = metric\n",
    "        self.nf = nfolds\n",
    "        self.v = verbose\n",
    "        self.is_reg = regression\n",
    "        self.stack = None\n",
    "    \n",
    "    def mse(self, actual, pred):\n",
    "        return mean_squared_error(actual, pred)\n",
    "    \n",
    "    def rsq(self, actual, pred):\n",
    "        return r2_score(actual, pred)\n",
    "    \n",
    "    def get_metric_calc(self, actual, pred):\n",
    "        if 'rmse' == self.metname:\n",
    "            return self.mse(actual, pred)\n",
    "        elif 'r2' == self.metname:\n",
    "            return self.rsq(actual, pred)\n",
    "    \n",
    "    def build_stack(self):\n",
    "        self.stack = StackingTransformer(self.l1, \n",
    "                                        regression=self.is_reg, \n",
    "                                        shuffle=True, \n",
    "                                        n_folds=self.nf, \n",
    "                                        metric=self.get_metric_calc, \n",
    "                                        verbose=self.v)\n",
    "    \n",
    "    def fit_stack(self):\n",
    "        return self.stack.fit(self.X, self.y)\n",
    "    \n",
    "    def transform(self):\n",
    "        self.X = self.stack.transform(self.X)\n",
    "        self.Xt = self.stack.transform(self.Xt)\n",
    "    \n",
    "    def fit_l2(self):\n",
    "        self.l2.fit(self.X, self.y)\n",
    "    \n",
    "    def predict(self):\n",
    "        self.yp = self.l2.predict(self.X)\n",
    "        self.ytp = self.l2.predict(self.Xt)\n",
    "    \n",
    "    def calculate_error(self, calc=None):\n",
    "        if calc:\n",
    "            y_err = calc(self.y, self.yp)\n",
    "            yp_err = calc(self.y, self.ytp)\n",
    "        else:\n",
    "            y_err = self.get_metric_calc(self.y, self.yp)\n",
    "            yt_err = self.get_metric_calc(self.yt, self.ytp)\n",
    "            \n",
    "        return [('Train err', y_err), ('Test err', yt_err)]\n",
    "    \n",
    "    def save_to_disk(self):\n",
    "        sname = self.prfx+'_vecstack_stack.pkl'\n",
    "        cname = self.prfx+'_vecstack_clf.pkl'\n",
    "        \n",
    "        with open('./data/'+sname, 'wb') as f:\n",
    "            pickle.dump(self.stack,f)\n",
    "        \n",
    "        with open('./data/'+cname, 'wb') as f:\n",
    "            pickle.dump(self.l2, f)\n",
    "    \n",
    "    def run(self):\n",
    "        self.build_stack()\n",
    "        self.fit_stack()\n",
    "        self.transform()\n",
    "        self.fit_l2()\n",
    "        self.predict()\n",
    "        self.save_to_disk()\n",
    "        return self.calculate_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "en = ElasticNet(alpha=0.01)\n",
    "# lass = Lasso(alpha=0.001, fit_intercept=False, max_iter=1000)\n",
    "ridge = Ridge(normalize=False, alpha=0.1, max_iter=1000)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, \n",
    "                               subsample=0.75, max_depth=15)\n",
    "ab = AdaBoostRegressor(n_estimators=100, learning_rate=0.01)\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                           gamma=0, subsample=0.5, \n",
    "                           max_depth=15, objective='reg:linear')\n",
    "randf = RandomForestRegressor(n_estimators=100, min_samples_split=10)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [get_metric_calc]\n",
      "variant:      [A]\n",
      "n_estimators: [5]\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    fold  0:  [28.62955409]\n",
      "    fold  1:  [23.46238485]\n",
      "    fold  2:  [24.46192645]\n",
      "    fold  3:  [23.80988442]\n",
      "    fold  4:  [24.51719549]\n",
      "    fold  5:  [27.19129348]\n",
      "    fold  6:  [28.73117538]\n",
      "    fold  7:  [24.46624948]\n",
      "    fold  8:  [27.29496441]\n",
      "    fold  9:  [23.36181634]\n",
      "    ----\n",
      "    MEAN:     [25.59264444] + [2.02295529]\n",
      "\n",
      "estimator  1: [ridge: Ridge]\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                # ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "base = './data/'\n",
    "prf = 'comb'\n",
    "vr = VecstackRunner(comb_train, y_train, \n",
    "                    comb_validation, y_validation, \n",
    "                    estimators, xgb, prfx=prf, nfolds=10)\n",
    "vr.run()\n",
    "\n",
    "# print mean_squared_error(y_validation, tc.predict(ts.transform(comb_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "print mean_squared_error(y_validation, tc.predict(ts.transform(comb_validation)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

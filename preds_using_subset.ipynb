{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename, valtype):\n",
    "    df = pd.read_csv(filename, low_memory=False, dtype=valtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dependent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16896</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "16896                  94.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(base+'fin_train_indeps.csv', encoding='utf8')\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis=1)\n",
    "y_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "21597                 100.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(base+'fin_test_indeps.csv', encoding='utf8')\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis=1)\n",
    "y_test.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read independent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = pd.read_csv(base+'fin_num_train_deps.csv')\n",
    "num_train = num_train.drop(['Unnamed: 0'], axis=1)\n",
    "num_test = pd.read_csv(base+'fin_num_test_deps.csv')\n",
    "num_test = num_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "cat_train = pd.read_csv(base+'fin_cat_train_deps.csv')\n",
    "cat_train = cat_train.drop(['Unnamed: 0'], axis=1)\n",
    "cat_test = pd.read_csv(base+'fin_cat_test_deps.csv')\n",
    "cat_test = cat_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "amen_train = pd.read_csv(base+'fin_amen_train_deps.csv')\n",
    "amen_train = amen_train.drop(['Unnamed: 0'], axis=1)\n",
    "amen_test = pd.read_csv(base+'fin_amen_test_deps.csv')\n",
    "amen_test = amen_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "comb_train = pd.read_csv(base+'fin_comb_train_deps.csv')\n",
    "comb_train = comb_train.drop(['Unnamed: 0'], axis=1)\n",
    "comb_test = pd.read_csv(base+'fin_comb_test_deps.csv')\n",
    "comb_test = comb_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test data into Holdout and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "idxs = np.random.randint(0, y_test.shape[0], y_test.shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = y_test.iloc[~y_test.index.isin(idxs)]\n",
    "y_holdout = y_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation = num_test.iloc[~num_test.index.isin(idxs)]\n",
    "num_holdout = num_test.iloc[idxs]\n",
    "\n",
    "cat_validation = cat_test.iloc[~cat_test.index.isin(idxs)]\n",
    "cat_holdout = cat_test.iloc[idxs]\n",
    "\n",
    "amen_validation = amen_test.iloc[~amen_test.index.isin(idxs)]\n",
    "amen_holdout = amen_test.iloc[idxs]\n",
    "\n",
    "comb_validation = comb_test.iloc[~comb_test.index.isin(idxs)]\n",
    "comb_holdout = comb_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective: Implement a wrapper for vecstack\n",
    "# InputL scikit model instances and training data\n",
    "# Output: Predictions\n",
    "\n",
    "import vecstack\n",
    "import xgboost\n",
    "import dill as pickle\n",
    "from copy import deepcopy \n",
    "from vecstack import StackingTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class VecstackRunner():\n",
    "\n",
    "    def __init__(self, X, y, Xt, yt, l1_estimators, l2_estimator, prfx='', metric='rmse', regression=True, nfolds=10, verbose=2):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Xt = Xt\n",
    "        self.yt = yt\n",
    "        self.yp = None\n",
    "        self.ytp = None\n",
    "        self.l1 = l1_estimators\n",
    "        self.l2 = l2_estimator\n",
    "        self.prfx = prfx\n",
    "        self.metname = metric\n",
    "        self.nf = nfolds\n",
    "        self.v = verbose\n",
    "        self.is_reg = regression\n",
    "        self.stack = None\n",
    "    \n",
    "    def mse(self, actual, pred):\n",
    "        return mean_squared_error(actual, pred)\n",
    "    \n",
    "    def rsq(self, actual, pred):\n",
    "        return r2_score(actual, pred)\n",
    "    \n",
    "    def get_metric_calc(self, actual, pred):\n",
    "        if 'rmse' == self.metname:\n",
    "            return self.mse(actual, pred)\n",
    "        elif 'r2' == self.metname:\n",
    "            return self.rsq(actual, pred)\n",
    "    \n",
    "    def build_stack(self):\n",
    "        self.stack = StackingTransformer(self.l1, \n",
    "                                        regression=self.is_reg, \n",
    "                                        shuffle=True, \n",
    "                                        n_folds=self.nf, \n",
    "                                        metric=self.get_metric_calc, \n",
    "                                        verbose=self.v)\n",
    "    \n",
    "    def fit_stack(self):\n",
    "        return self.stack.fit(self.X, self.y)\n",
    "    \n",
    "    def transform(self):\n",
    "        self.X = self.stack.transform(self.X)\n",
    "        self.Xt = self.stack.transform(self.Xt)\n",
    "    \n",
    "    def fit_l2(self):\n",
    "        self.l2.fit(self.X, self.y)\n",
    "    \n",
    "    def predict(self):\n",
    "        self.yp = self.l2.predict(self.X)\n",
    "        self.ytp = self.l2.predict(self.Xt)\n",
    "    \n",
    "    def calculate_error(self, calc=None):\n",
    "        if calc:\n",
    "            y_err = calc(self.y, self.yp)\n",
    "            yp_err = calc(self.y, self.ytp)\n",
    "        else:\n",
    "            y_err = self.get_metric_calc(self.y, self.yp)\n",
    "            yt_err = self.get_metric_calc(self.yt, self.ytp)\n",
    "            \n",
    "        return [('Train err', y_err), ('Test err', yt_err)]\n",
    "    \n",
    "    def save_to_disk(self):\n",
    "        sname = self.prfx+'_vecstack_stack.pkl'\n",
    "        cname = self.prfx+'_vecstack_clf.pkl'\n",
    "        \n",
    "        with open('/tmp/'+sname, 'wb') as f:\n",
    "            pickle.dump(self.stack,f)\n",
    "        \n",
    "        with open('/tmp/'+cname, 'wb') as f:\n",
    "            pickle.dump(self.l2, f)\n",
    "    \n",
    "    def run(self):\n",
    "        self.build_stack()\n",
    "        self.fit_stack()\n",
    "        self.transform()\n",
    "        self.fit_l2()\n",
    "        self.predict()\n",
    "        self.save_to_disk()\n",
    "        return self.calculate_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "en = ElasticNet(alpha=0.001)\n",
    "lass = Lasso(alpha=0.001, fit_intercept=False, max_iter=10000)\n",
    "ridge = Ridge(normalize=False, alpha=0.1, max_iter=10000)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, \n",
    "                               subsample=0.75, max_depth=15)\n",
    "ab = AdaBoostRegressor(n_estimators=100, learning_rate=0.01)\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                           gamma=0, subsample=0.5, \n",
    "                           max_depth=15, objective='reg:linear')\n",
    "randf = RandomForestRegressor(n_estimators=100, min_samples_split=10)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator ElasticNet from version 0.18.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator Lasso from version 0.18.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator Ridge from version 0.18.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 0.18.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator AdaBoostRegressor from version 0.18.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.18.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.18.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lass: Lasso]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [ridge: Ridge]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [gb: GradientBoostingRegressor]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingRegressor' object has no attribute 'n_features_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fa54e2dabbfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mXp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/vecstack/coresk.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, is_train_set)\u001b[0m\n\u001b[1;32m    691\u001b[0m                                                                                     \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                                                                                     \u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                                                                                     transform=self.transform_pred)\n\u001b[0m\u001b[1;32m    694\u001b[0m                     \u001b[0;31m# Print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/vecstack/coresk.pyc\u001b[0m in \u001b[0;36m_estimator_action\u001b[0;34m(self, estimator, X_train, y_train, X_test, sample_weight, action, transform)\u001b[0m\n\u001b[1;32m    843\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'predict'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \"\"\"\n\u001b[1;32m   1891\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# not doing input validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_init_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n\u001b[1;32m   1123\u001b[0m                 self.n_features_, X.shape[1]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GradientBoostingRegressor' object has no attribute 'n_features_'"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "prf = 'num'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "    \n",
    "Xt = ts.transform(num_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(num_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './data/cat_vecstack_stack.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-594ae5b9952a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_vecstack_stack.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './data/cat_vecstack_stack.pkl'"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "prf = 'cat'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "Xt = ts.transform(cat_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(cat_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [en: ElasticNet]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lass: Lasso]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [ridge: Ridge]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [gb: GradientBoostingRegressor]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingRegressor' object has no attribute 'n_features_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-476bcc0f316c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamen_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mXp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/vecstack/coresk.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, is_train_set)\u001b[0m\n\u001b[1;32m    691\u001b[0m                                                                                     \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                                                                                     \u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                                                                                     transform=self.transform_pred)\n\u001b[0m\u001b[1;32m    694\u001b[0m                     \u001b[0;31m# Print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/vecstack/coresk.pyc\u001b[0m in \u001b[0;36m_estimator_action\u001b[0;34m(self, estimator, X_train, y_train, X_test, sample_weight, action, transform)\u001b[0m\n\u001b[1;32m    843\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'predict'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \"\"\"\n\u001b[1;32m   1891\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# not doing input validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_init_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n\u001b[1;32m   1123\u001b[0m                 self.n_features_, X.shape[1]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GradientBoostingRegressor' object has no attribute 'n_features_'"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "prf = 'amen'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "Xt = ts.transform(amen_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(amen_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "prf = 'comb'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "Xt = ts.transform(comb_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(comb_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

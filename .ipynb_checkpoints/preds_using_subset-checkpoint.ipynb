{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename, valtype):\n",
    "    df = pd.read_csv(filename, low_memory=False, dtype=valtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dependent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16896</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "16896                  94.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(base+'fin_train_indeps.csv', encoding='utf8')\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis=1)\n",
    "y_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "21597                 100.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(base+'fin_test_indeps.csv', encoding='utf8')\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis=1)\n",
    "y_test.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read independent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = pd.read_csv(base+'fin_num_train_deps.csv')\n",
    "num_train = num_train.drop(['Unnamed: 0'], axis=1)\n",
    "num_test = pd.read_csv(base+'fin_num_test_deps.csv')\n",
    "num_test = num_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "cat_train = pd.read_csv(base+'fin_cat_train_deps.csv')\n",
    "cat_train = cat_train.drop(['Unnamed: 0'], axis=1)\n",
    "cat_test = pd.read_csv(base+'fin_cat_test_deps.csv')\n",
    "cat_test = cat_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "amen_train = pd.read_csv(base+'fin_amen_train_deps.csv')\n",
    "amen_train = amen_train.drop(['Unnamed: 0'], axis=1)\n",
    "amen_test = pd.read_csv(base+'fin_amen_test_deps.csv')\n",
    "amen_test = amen_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "comb_train = pd.read_csv(base+'fin_comb_train_deps.csv')\n",
    "comb_train = comb_train.drop(['Unnamed: 0'], axis=1)\n",
    "comb_test = pd.read_csv(base+'fin_comb_test_deps.csv')\n",
    "comb_test = comb_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test data into Holdout and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "idxs = np.random.randint(0, y_test.shape[0], y_test.shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = y_test.iloc[~y_test.index.isin(idxs)]\n",
    "y_holdout = y_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation = num_test.iloc[~num_test.index.isin(idxs)]\n",
    "num_holdout = num_test.iloc[idxs]\n",
    "\n",
    "cat_validation = cat_test.iloc[~cat_test.index.isin(idxs)]\n",
    "cat_holdout = cat_test.iloc[idxs]\n",
    "\n",
    "amen_validation = amen_test.iloc[~amen_test.index.isin(idxs)]\n",
    "amen_holdout = amen_test.iloc[idxs]\n",
    "\n",
    "comb_validation = comb_test.iloc[~comb_test.index.isin(idxs)]\n",
    "comb_holdout = comb_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective: Implement a wrapper for vecstack\n",
    "# InputL scikit model instances and training data\n",
    "# Output: Predictions\n",
    "\n",
    "import vecstack\n",
    "import xgboost\n",
    "import dill as pickle\n",
    "from copy import deepcopy \n",
    "from vecstack import StackingTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class VecstackRunner():\n",
    "\n",
    "    def __init__(self, X, y, Xt, yt, l1_estimators, l2_estimator, prfx='', metric='rmse', regression=True, nfolds=10, verbose=2):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Xt = Xt\n",
    "        self.yt = yt\n",
    "        self.yp = None\n",
    "        self.ytp = None\n",
    "        self.l1 = l1_estimators\n",
    "        self.l2 = l2_estimator\n",
    "        self.prfx = prfx\n",
    "        self.metname = metric\n",
    "        self.nf = nfolds\n",
    "        self.v = verbose\n",
    "        self.is_reg = regression\n",
    "        self.stack = None\n",
    "    \n",
    "    def mse(self, actual, pred):\n",
    "        return mean_squared_error(actual, pred)\n",
    "    \n",
    "    def rsq(self, actual, pred):\n",
    "        return r2_score(actual, pred)\n",
    "    \n",
    "    def get_metric_calc(self, actual, pred):\n",
    "        if 'rmse' == self.metname:\n",
    "            return self.mse(actual, pred)\n",
    "        elif 'r2' == self.metname:\n",
    "            return self.rsq(actual, pred)\n",
    "    \n",
    "    def build_stack(self):\n",
    "        self.stack = StackingTransformer(self.l1, \n",
    "                                        regression=self.is_reg, \n",
    "                                        shuffle=True, \n",
    "                                        n_folds=self.nf, \n",
    "                                        metric=self.get_metric_calc, \n",
    "                                        verbose=self.v)\n",
    "    \n",
    "    def fit_stack(self):\n",
    "        return self.stack.fit(self.X, self.y)\n",
    "    \n",
    "    def transform(self):\n",
    "        self.X = self.stack.transform(self.X)\n",
    "        self.Xt = self.stack.transform(self.Xt)\n",
    "    \n",
    "    def fit_l2(self):\n",
    "        self.l2.fit(self.X, self.y)\n",
    "    \n",
    "    def predict(self):\n",
    "        self.yp = self.l2.predict(self.X)\n",
    "        self.ytp = self.l2.predict(self.Xt)\n",
    "    \n",
    "    def calculate_error(self, calc=None):\n",
    "        if calc:\n",
    "            y_err = calc(self.y, self.yp)\n",
    "            yp_err = calc(self.y, self.ytp)\n",
    "        else:\n",
    "            y_err = self.get_metric_calc(self.y, self.yp)\n",
    "            yt_err = self.get_metric_calc(self.yt, self.ytp)\n",
    "            \n",
    "        return [('Train err', y_err), ('Test err', yt_err)]\n",
    "    \n",
    "    def save_to_disk(self):\n",
    "        sname = self.prfx+'_vecstack_stack.pkl'\n",
    "        cname = self.prfx+'_vecstack_clf.pkl'\n",
    "        \n",
    "        with open('/tmp/'+sname, 'wb') as f:\n",
    "            pickle.dump(self.stack,f)\n",
    "        \n",
    "        with open('/tmp/'+cname, 'wb') as f:\n",
    "            pickle.dump(self.l2, f)\n",
    "    \n",
    "    def run(self):\n",
    "        self.build_stack()\n",
    "        self.fit_stack()\n",
    "        self.transform()\n",
    "        self.fit_l2()\n",
    "        self.predict()\n",
    "        self.save_to_disk()\n",
    "        return self.calculate_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "en = ElasticNet(alpha=0.001)\n",
    "lass = Lasso(alpha=0.001, fit_intercept=False, max_iter=10000)\n",
    "ridge = Ridge(normalize=False, alpha=0.1, max_iter=10000)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, \n",
    "                               subsample=0.75, max_depth=15)\n",
    "ab = AdaBoostRegressor(n_estimators=100, learning_rate=0.01)\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                           gamma=0, subsample=0.5, \n",
    "                           max_depth=15, objective='reg:linear')\n",
    "randf = RandomForestRegressor(n_estimators=100, min_samples_split=10)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "prf = 'num'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "    \n",
    "Xt = ts.transform(num_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(num_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "prf = 'cat'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "Xt = ts.transform(cat_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(cat_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "prf = 'amen'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "Xt = ts.transform(amen_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(amen_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "prf = 'comb'\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "Xt = ts.transform(comb_train)\n",
    "Xp = tc.predict(Xt)\n",
    "y = y_train\n",
    "\n",
    "Xvt = ts.transform(comb_test)\n",
    "Xvp = tc.predict(Xvt)\n",
    "yv = y_test\n",
    "\n",
    "print '####################'\n",
    "print 'Column: %s' % prf\n",
    "print 'Train: '\n",
    "print 'MSE: %s' % mean_squared_error(y, Xp)\n",
    "print 'R2: %s' % r2_score(y, Xp) \n",
    "print 'Test: '\n",
    "print 'MSE: %s' % mean_squared_error(yv, Xvp)\n",
    "print 'R2: %s' % r2_score(yv, Xvp)\n",
    "print '####################\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
